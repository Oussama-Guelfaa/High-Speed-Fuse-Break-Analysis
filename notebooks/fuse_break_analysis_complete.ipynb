{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Analyse de la Rupture de Fusibles à Haute Vitesse\n",
                "\n",
                "Ce notebook contient le code complet pour analyser des vidéos de radiographie à rayons X à haute vitesse de fusibles industriels. Il mesure la distance entre les éléments du fusible pendant les événements de rupture.\n",
                "\n",
                "## Aperçu\n",
                "\n",
                "Les fusibles à haute capacité de rupture (HRC) sont des composants de sécurité essentiels dans les systèmes électriques. Lorsqu'un court-circuit se produit, ces fusibles doivent se rompre rapidement pour protéger le circuit. Ce notebook analyse les vidéos de radiographie à rayons X des événements de rupture de fusibles pour mesurer la distance entre les éléments du fusible au fil du temps, fournissant des informations sur la dynamique de rupture."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Importation des bibliothèques"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import numpy as np\n",
                "import cv2\n",
                "import matplotlib.pyplot as plt\n",
                "from typing import List, Dict, Tuple, Optional\n",
                "import pandas as pd\n",
                "import time\n",
                "import logging\n",
                "from dataclasses import dataclass\n",
                "from scipy.signal import savgol_filter\n",
                "from skimage import measure\n",
                "\n",
                "# Configuration du logging\n",
                "logging.basicConfig(\n",
                "    level=logging.INFO,\n",
                "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
                ")\n",
                "logger = logging.getLogger(__name__)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Module de traitement vidéo"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "@dataclass\n",
                "class VideoFrame:\n",
                "    \"\"\"Classe pour stocker les données et métadonnées d'une frame vidéo.\"\"\"\n",
                "    index: int\n",
                "    data: np.ndarray\n",
                "    timestamp: Optional[float] = None\n",
                "\n",
                "\n",
                "class VideoProcessor:\n",
                "    \"\"\"Classe pour traiter les vidéos à haute vitesse d'événements de rupture de fusibles.\"\"\"\n",
                "    \n",
                "    def __init__(self, video_path: str):\n",
                "        \"\"\"\n",
                "        Initialise le processeur vidéo.\n",
                "        \n",
                "        Args:\n",
                "            video_path: Chemin vers le fichier vidéo\n",
                "        \"\"\"\n",
                "        self.video_path = video_path\n",
                "        self.video_obj = None\n",
                "        self.frames = []\n",
                "        self.height = 0\n",
                "        self.width = 0\n",
                "        self.fps = 0\n",
                "        self.frame_count = 0\n",
                "        \n",
                "    def load_video(self) -> bool:\n",
                "        \"\"\"\n",
                "        Charge le fichier vidéo et extrait les propriétés de base.\n",
                "        \n",
                "        Returns:\n",
                "            bool: True si la vidéo a été chargée avec succès, False sinon\n",
                "        \"\"\"\n",
                "        try:\n",
                "            self.video_obj = cv2.VideoCapture(self.video_path)\n",
                "            if not self.video_obj.isOpened():\n",
                "                print(f\"Erreur: Impossible d'ouvrir le fichier vidéo {self.video_path}\")\n",
                "                return False\n",
                "                \n",
                "            # Obtenir les propriétés de la vidéo\n",
                "            self.width = int(self.video_obj.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
                "            self.height = int(self.video_obj.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
                "            self.fps = self.video_obj.get(cv2.CAP_PROP_FPS)\n",
                "            self.frame_count = int(self.video_obj.get(cv2.CAP_PROP_FRAME_COUNT))\n",
                "            \n",
                "            print(f\"Vidéo chargée: {self.width}x{self.height}, {self.fps} fps, {self.frame_count} frames\")\n",
                "            return True\n",
                "            \n",
                "        except Exception as e:\n",
                "            print(f\"Erreur lors du chargement de la vidéo: {str(e)}\")\n",
                "            return False\n",
                "    \n",
                "    def extract_all_frames(self) -> List[VideoFrame]:\n",
                "        \"\"\"\n",
                "        Extrait toutes les frames de la vidéo et les stocke.\n",
                "        \n",
                "        Returns:\n",
                "            List[VideoFrame]: Liste des frames vidéo\n",
                "        \"\"\"\n",
                "        if self.video_obj is None or not self.video_obj.isOpened():\n",
                "            if not self.load_video():\n",
                "                return []\n",
                "        \n",
                "        self.frames = []\n",
                "        frame_idx = 0\n",
                "        \n",
                "        while True:\n",
                "            ret, frame = self.video_obj.read()\n",
                "            if not ret:\n",
                "                break\n",
                "                \n",
                "            # Convertir en niveaux de gris si la frame est en couleur\n",
                "            if len(frame.shape) == 3:\n",
                "                gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
                "            else:\n",
                "                gray_frame = frame\n",
                "                \n",
                "            # Stocker la frame\n",
                "            self.frames.append(VideoFrame(\n",
                "                index=frame_idx,\n",
                "                data=gray_frame,\n",
                "                timestamp=frame_idx / self.fps if self.fps > 0 else None\n",
                "            ))\n",
                "            \n",
                "            frame_idx += 1\n",
                "            \n",
                "        print(f\"Extraction de {len(self.frames)} frames\")\n",
                "        return self.frames\n",
                "    \n",
                "    def get_frame(self, index: int) -> Optional[np.ndarray]:\n",
                "        \"\"\"\n",
                "        Récupère une frame spécifique par son index.\n",
                "        \n",
                "        Args:\n",
                "            index: Index de la frame\n",
                "            \n",
                "        Returns:\n",
                "            np.ndarray: Données de la frame ou None si l'index est invalide\n",
                "        \"\"\"\n",
                "        if 0 <= index < len(self.frames):\n",
                "            return self.frames[index].data\n",
                "        return None\n",
                "    \n",
                "    def release(self):\n",
                "        \"\"\"Libère les ressources vidéo.\"\"\"\n",
                "        if self.video_obj is not None and self.video_obj.isOpened():\n",
                "            self.video_obj.release()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Module de traitement d'image"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class FuseImageProcessor:\n",
                "    \"\"\"Classe pour traiter les images à rayons X de fusibles et mesurer les distances de rupture.\"\"\"\n",
                "    \n",
                "    def __init__(self, calibration_value_mm: float = 2.0):\n",
                "        \"\"\"\n",
                "        Initialise le processeur d'image de fusible.\n",
                "        \n",
                "        Args:\n",
                "            calibration_value_mm: La hauteur H connue du fusible en mm (par défaut: 2.0)\n",
                "        \"\"\"\n",
                "        self.calibration_value_mm = calibration_value_mm\n",
                "        self.pixels_per_mm = None\n",
                "        self.calibrated = False\n",
                "    \n",
                "    def preprocess_image(self, image: np.ndarray) -> np.ndarray:\n",
                "        \"\"\"\n",
                "        Prétraite l'image pour une meilleure segmentation.\n",
                "        \n",
                "        Args:\n",
                "            image: Image en niveaux de gris d'entrée\n",
                "            \n",
                "        Returns:\n",
                "            np.ndarray: Image prétraitée\n",
                "        \"\"\"\n",
                "        # Appliquer un flou gaussien pour réduire le bruit\n",
                "        blurred = cv2.GaussianBlur(image, (5, 5), 0)\n",
                "        \n",
                "        # Utiliser le seuillage d'Otsu qui est meilleur pour les images bimodales comme les rayons X\n",
                "        _, thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
                "        \n",
                "        # Appliquer des opérations morphologiques pour nettoyer l'image binaire\n",
                "        kernel = np.ones((3, 3), np.uint8)\n",
                "        opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)\n",
                "        \n",
                "        # Appliquer une fermeture pour combler les petits trous\n",
                "        kernel = np.ones((5, 5), np.uint8)\n",
                "        cleaned = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
                "        \n",
                "        return cleaned\n",
                "    \n",
                "    def segment_fuse_elements(self, image: np.ndarray) -> Tuple[np.ndarray, List]:\n",
                "        \"\"\"\n",
                "        Segmente les éléments du fusible (parties noires) dans l'image.\n",
                "        \n",
                "        Args:\n",
                "            image: Image en niveaux de gris d'entrée\n",
                "            \n",
                "        Returns:\n",
                "            Tuple contenant:\n",
                "                - Masque binaire des éléments segmentés\n",
                "                - Liste des propriétés pour chaque région détectée\n",
                "        \"\"\"\n",
                "        # Prétraiter l'image\n",
                "        binary = self.preprocess_image(image)\n",
                "        \n",
                "        # Trouver les composantes connexes\n",
                "        labeled_img = measure.label(binary)\n",
                "        regions = measure.regionprops(labeled_img)\n",
                "        \n",
                "        # Filtrer les régions par surface pour éliminer le bruit\n",
                "        min_area = 100  # Ajuster en fonction de la résolution de l'image\n",
                "        valid_regions = [r for r in regions if r.area >= min_area]\n",
                "        \n",
                "        # Créer un masque avec uniquement les régions valides\n",
                "        mask = np.zeros_like(binary)\n",
                "        for region in valid_regions:\n",
                "            for coord in region.coords:\n",
                "                mask[coord[0], coord[1]] = 255\n",
                "                \n",
                "        return mask, valid_regions\n",
                "    \n",
                "    def calibrate(self, reference_image: np.ndarray) -> float:\n",
                "        \"\"\"\n",
                "        Calibre le système de mesure en utilisant une image de référence.\n",
                "        \n",
                "        Args:\n",
                "            reference_image: Image de référence où H est connu\n",
                "            \n",
                "        Returns:\n",
                "            float: Facteur de calibration en pixels par millimètre\n",
                "        \"\"\"\n",
                "        # Segmenter les éléments du fusible\n",
                "        mask, regions = self.segment_fuse_elements(reference_image)\n",
                "        \n",
                "        if len(regions) < 1:\n",
                "            raise ValueError(\"Aucun élément de fusible détecté dans l'image de référence\")\n",
                "        \n",
                "        # Trouver la hauteur (H) en pixels\n",
                "        # Pour la calibration, nous utilisons la première frame où le fusible est intact\n",
                "        heights = [r.bbox[2] - r.bbox[0] for r in regions]\n",
                "        h_pixels = max(heights)  # Utiliser la plus grande hauteur comme H\n",
                "        \n",
                "        # Calculer les pixels par mm\n",
                "        self.pixels_per_mm = h_pixels / self.calibration_value_mm\n",
                "        self.calibrated = True\n",
                "        \n",
                "        print(f\"Calibration terminée: {self.pixels_per_mm:.2f} pixels/mm\")\n",
                "        return self.pixels_per_mm\n",
                "    \n",
                "    def measure_distance(self, image: np.ndarray) -> Optional[float]:\n",
                "        \"\"\"\n",
                "        Mesure la distance entre les éléments du fusible en millimètres.\n",
                "        \n",
                "        Args:\n",
                "            image: Image en niveaux de gris d'entrée\n",
                "            \n",
                "        Returns:\n",
                "            float: Distance en millimètres ou None si la mesure a échoué\n",
                "        \"\"\"\n",
                "        if not self.calibrated:\n",
                "            raise ValueError(\"Calibration requise avant la mesure\")\n",
                "        \n",
                "        # Segmenter les éléments du fusible\n",
                "        mask, regions = self.segment_fuse_elements(image)\n",
                "        \n",
                "        # Vérifier si nous avons assez de régions pour mesurer\n",
                "        if len(regions) < 2:\n",
                "            # Si nous n'avons qu'une seule région, le fusible est probablement intact\n",
                "            if len(regions) == 1:\n",
                "                # Vérifier si la région couvre la majeure partie de la largeur\n",
                "                region = regions[0]\n",
                "                width = image.shape[1]\n",
                "                region_width = region.bbox[3] - region.bbox[1]\n",
                "                \n",
                "                if region_width > 0.5 * width:\n",
                "                    # C'est probablement un fusible intact\n",
                "                    return 0.0\n",
                "            \n",
                "            # Pour les frames avant le début de la rupture\n",
                "            # Vérifier s'il s'agit d'une frame précoce (fusible intact)\n",
                "            # Rechercher des pixels sombres au milieu de l'image\n",
                "            h, w = image.shape\n",
                "            center_region = image[h//4:3*h//4, w//4:3*w//4]\n",
                "            if np.mean(center_region) < 100:  # Ajuster le seuil si nécessaire\n",
                "                return 0.0\n",
                "                \n",
                "            return None\n",
                "        \n",
                "        # Pour les frames avec plusieurs régions, nous devons identifier les principales parties du fusible\n",
                "        \n",
                "        # Filtrer les régions par taille pour se concentrer sur les principales parties du fusible\n",
                "        min_area_ratio = 0.01  # Surface minimale en fraction de la plus grande région\n",
                "        largest_area = max(r.area for r in regions)\n",
                "        significant_regions = [r for r in regions if r.area > min_area_ratio * largest_area]\n",
                "        \n",
                "        if len(significant_regions) < 2:\n",
                "            return 0.0  # Pas assez de régions significatives\n",
                "            \n",
                "        # Trier les régions horizontalement (par coordonnée x)\n",
                "        sorted_regions = sorted(significant_regions, key=lambda r: r.centroid[1])\n",
                "        \n",
                "        # Trouver les régions significatives les plus à gauche et les plus à droite\n",
                "        left_regions = sorted_regions[:len(sorted_regions)//2]\n",
                "        right_regions = sorted_regions[len(sorted_regions)//2:]\n",
                "        \n",
                "        if not left_regions or not right_regions:\n",
                "            return 0.0\n",
                "            \n",
                "        # Trouver le point le plus à droite de toutes les régions de gauche\n",
                "        left_edge = max(r.bbox[1] + r.bbox[3] for r in left_regions)  # bord droit des régions de gauche\n",
                "        \n",
                "        # Trouver le point le plus à gauche de toutes les régions de droite\n",
                "        right_edge = min(r.bbox[1] for r in right_regions)  # bord gauche des régions de droite\n",
                "        \n",
                "        # Calculer la distance\n",
                "        distance_pixels = max(0, right_edge - left_edge)\n",
                "        distance_mm = distance_pixels / self.pixels_per_mm\n",
                "        \n",
                "        # Appliquer un seuil pour éviter le bruit\n",
                "        if distance_mm < 0.1:  # Distance minimale significative\n",
                "            return 0.0\n",
                "            \n",
                "        return distance_mm\n",
                "    \n",
                "    def visualize_measurement(self, image: np.ndarray, distance_mm: float) -> np.ndarray:\n",
                "        \"\"\"\n",
                "        Crée une visualisation de la mesure sur l'image.\n",
                "        \n",
                "        Args:\n",
                "            image: Image en niveaux de gris d'entrée\n",
                "            distance_mm: Distance mesurée en millimètres\n",
                "            \n",
                "        Returns:\n",
                "            np.ndarray: Image de visualisation avec annotations\n",
                "        \"\"\"\n",
                "        # Convertir l'image en niveaux de gris en couleur pour la visualisation\n",
                "        vis_img = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
                "        \n",
                "        # Segmenter les éléments du fusible\n",
                "        mask, regions = self.segment_fuse_elements(image)\n",
                "        \n",
                "        # Dessiner les contours autour des régions détectées\n",
                "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
                "        cv2.drawContours(vis_img, contours, -1, (0, 255, 0), 2)\n",
                "        \n",
                "        # Ajouter le texte de mesure de distance\n",
                "        cv2.putText(\n",
                "            vis_img, \n",
                "            f\"d = {distance_mm:.3f} mm\", \n",
                "            (10, 30), \n",
                "            cv2.FONT_HERSHEY_SIMPLEX, \n",
                "            0.7, \n",
                "            (0, 0, 255), \n",
                "            2\n",
                "        )\n",
                "        \n",
                "        return vis_img"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
